{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de datos\n",
    "\n",
    "- Datos de ejemplo: Problema no linealmente separable\n",
    "- DataSet y DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "data, labels = sklearn.datasets.make_circles(n_samples=1000, noise=0.2, factor=0.25)\n",
    "#data, labels = sklearn.datasets.make_moons(n_samples=1000, noise=0.2)\n",
    "#data, labels = sklearn.datasets.make_blobs(n_samples=[250]*4, n_features=2, cluster_std=0.5,\n",
    "#                                          centers=np.array([[-1, 1], [1, 1], [-1, -1], [1, -1]]))\n",
    "#labels[labels==2] = 1; labels[labels==3] = 0;\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\n",
    "for k, marker in enumerate(['x', 'o']):\n",
    "    ax.scatter(data[labels==k, 0], data[labels==k, 1], c='k', s=20, marker=marker, alpha=0.75)\n",
    "    \n",
    "# Para las gráficas\n",
    "x_min, x_max = data[:, 0].min() - 0.5, data[:, 0].max() + 0.5\n",
    "y_min, y_max = data[:, 1].min() - 0.5, data[:, 1].max() + 0.5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "import sklearn.model_selection\n",
    "# Separamos el data set en entrenamiento y validación\n",
    "train_idx, valid_idx = next(sklearn.model_selection.ShuffleSplit(train_size=0.75).split(data, labels))\n",
    "\n",
    "\n",
    "# Crear conjuntos de entrenamiento y prueba\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset \n",
    "\n",
    "# Creamos un conjunto de datos en formato tensor\n",
    "torch_set = TensorDataset(torch.from_numpy(data.astype('float32')), \n",
    "                          torch.from_numpy(labels.astype('float32')))\n",
    "\n",
    "# Data loader de entrenamiento\n",
    "torch_train_loader = DataLoader(Subset(torch_set, train_idx), shuffle=True, batch_size=32)\n",
    "# Data loader de validación\n",
    "torch_valid_loader = DataLoader(Subset(torch_set, valid_idx), shuffle=False, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrón multicapa\n",
    "\n",
    "- ¿Cómo cambia el resultado según la cantidad de capas y neuronas ocultas?\n",
    "- ¿Cómo cambia el resultado usando distintas inicializaciones?\n",
    "- ¿Cómo cambia el resultado usando distintas funciones de activación?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, neurons=[2, 1]): \n",
    "        super(type(self), self).__init__()\n",
    "        \n",
    "        # Podemos usar ModuleList para registrar una lista de submodulos\n",
    "        self.hidden = torch.nn.ModuleList()\n",
    "        for k in range(len(neurons)-2):\n",
    "            self.hidden.append(torch.nn.Linear(neurons[k], neurons[k+1]))                \n",
    "        \n",
    "        self.output = torch.nn.Linear(neurons[-2], neurons[-1])\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # ModuleList es un objeto iterable\n",
    "        for k, layer in enumerate(self.hidden):\n",
    "            x = self.activation(layer(x))\n",
    "\n",
    "        return self.output(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_step(batch): \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch\n",
    "    yhat = model.forward(x)\n",
    "    loss = criterion(yhat, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_one_step(batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, y = batch\n",
    "        yhat = model.forward(x)\n",
    "        loss = criterion(yhat, y)\n",
    "        yhat = (torch.sigmoid(yhat) > 0.5).float()\n",
    "        return yhat, y.unsqueeze(1), loss.item()\n",
    "\n",
    "def draw_plots(epoch):\n",
    "    XY = torch.from_numpy(np.c_[xx.ravel(), yy.ravel()].astype('float32'))\n",
    "    Z = torch.sigmoid(model.forward(XY)).detach().numpy().reshape(xx.shape) \n",
    "    [ax_.cla() for ax_ in ax]\n",
    "    ax[0].contourf(xx, yy, Z, cmap=plt.cm.RdBu_r, alpha=1., vmin=0, vmax=1)\n",
    "    for i, (marker, name) in enumerate(zip(['o', 'x'], ['Train', 'Test'])):\n",
    "        ax[0].scatter(data[labels==i, 0], data[labels==i, 1], color='k', s=10, marker=marker, alpha=0.5)\n",
    "        ax[1].plot(np.arange(0, epoch+1, step=1), running_loss[:epoch+1, i], '-', label=name+\" cost\")\n",
    "    plt.legend(); ax[1].grid()\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 3.5), tight_layout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234) # Inicialización\n",
    "\n",
    "neurons = [2, 2, 1] # Arquitectura\n",
    "model = MultiLayerPerceptron(neurons)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "max_epochs = 100    \n",
    "running_loss = np.zeros(shape=(max_epochs, 2))\n",
    "best_valid_loss = np.inf\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss, valid_loss = 0.0, 0.0\n",
    "    for batch in torch_train_loader:\n",
    "        train_loss += train_one_step(batch)\n",
    "    running_loss[epoch, 0] = train_loss/torch_train_loader.dataset.__len__()    \n",
    "    # Loop de validación\n",
    "    for batch in torch_valid_loader:\n",
    "        valid_loss += evaluate_one_step(batch)[-1]\n",
    "    running_loss[epoch, 1] = valid_loss/torch_valid_loader.dataset.__len__()    \n",
    "    # Guardar modelo si es el mejor hasta ahora    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save({'current_epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'current_valid_loss': valid_loss}, \n",
    "                   'best_model.pt')\n",
    "    draw_plots(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cada neurona es un hiperplano\n",
    "- La primera capa son hiperplanos en el espacio de los datos\n",
    "- La segunda capa es un hiperplano en la salida de la primera capa\n",
    "- La segunda capa no es un hiperplano en el espacio de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiLayerPerceptron(neurons)\n",
    "model.load_state_dict(torch.load('best_model.pt')['model_state_dict'])\n",
    "\n",
    "XY = torch.from_numpy(np.c_[xx.ravel(), yy.ravel()].astype('float32'))\n",
    "Z = model.activation(model.hidden[0](XY)).detach().numpy()\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 7), tight_layout=True)\n",
    "for k in range(2):\n",
    "    ax[0, k].set_title(k+1)\n",
    "    ax[0, k].contourf(xx, yy, Z[:, k].reshape(xx.shape), \n",
    "                   cmap=plt.cm.RdBu_r, alpha=1., vmin=0, vmax=1)\n",
    "    for i, (marker, name) in enumerate(zip(['o', 'x'], ['Train', 'Test'])):\n",
    "        ax[0, k].scatter(data[labels==i, 0], data[labels==i, 1], color='k', s=10, marker=marker, alpha=0.5)\n",
    "\n",
    "Z = model.activation(model.forward(XY)).detach().numpy()\n",
    "ax[1, 1].contourf(xx, yy, Z.reshape(xx.shape), cmap=plt.cm.RdBu_r, alpha=1.)\n",
    "for i, (marker, name) in enumerate(zip(['o', 'x'], ['Train', 'Test'])):\n",
    "    ax[1, 1].scatter(data[labels==i, 0], data[labels==i, 1], color='k', s=10, marker=marker, alpha=0.5)\n",
    "\n",
    "Z = model.activation(model.output(XY)).detach().numpy()\n",
    "ax[1, 0].contourf(xx, yy, Z.reshape(xx.shape), cmap=plt.cm.RdBu_r, alpha=1.)\n",
    "ax[1, 0].set_xlim([0, 1]); ax[1, 0].set_ylim([0, 1]);\n",
    "ax[1, 0].set_xlabel('1'); ax[1, 0].set_ylabel('2');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento usando Ignite\n",
    "\n",
    "Ignite es una librería de alto nivel \n",
    "\n",
    "Provee engines, eventos, manejadores y métricas\n",
    "\n",
    "- Los engines se encargan de entrenar y evaluar la red. Se ponen en marcha usando el atributo `run`\n",
    "- Una métrica es un valor con el que evaluamos nuestra red (Loss, accuracy, f1-score)\n",
    "- Los manejadores nos permiten realizar acciones cuando se cumple un evento, por ejemplo\n",
    "    - Imprimir los resultados\n",
    "    - Guardar el mejor modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Loss\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "\n",
    "\n",
    "torch.manual_seed(1234) # Inicialización\n",
    "neurons = [2, 10, 1]\n",
    "model = MultiLayerPerceptron(neurons)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "max_epochs = 100  \n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion) # Creo un engine para entrenar\n",
    "metrics = {'Loss': Loss(criterion)}\n",
    "evaluator = create_supervised_evaluator(model, metrics=metrics) # Creo un engine para validar\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=10)) # Cada 10 epocas\n",
    "def log_results(engine):\n",
    "    evaluator.run(torch_valid_loader) # Evaluo el conjunto de validación\n",
    "    loss = evaluator.state.metrics['Loss']\n",
    "    print(f\"Epoca: {engine.state.epoch} \\t Loss: {loss:.2f}\")\n",
    "    \n",
    "best_model_handler = ModelCheckpoint(dirname='.', require_empty=False, filename_prefix=\"best\", n_saved=1,\n",
    "                                     score_function=lambda engine: -engine.state.metrics['Loss'],\n",
    "                                     score_name=\"val_loss\")\n",
    "\n",
    "evaluator.add_event_handler(Events.COMPLETED, # Esto se ejecuta cada ves que termine el loop de validación\n",
    "                            best_model_handler, {'mymodel': model})\n",
    "\n",
    "trainer.run(torch_train_loader, max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiLayerPerceptron(neurons)\n",
    "model.load_state_dict(torch.load('best_mymodel_val_loss=-2.8199.pt'))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3.5), tight_layout=True)\n",
    "Z = model.activation(model.forward(XY)).detach().numpy()\n",
    "ax.contourf(xx, yy, Z.reshape(xx.shape), cmap=plt.cm.RdBu_r, alpha=1.)\n",
    "for i, (marker, name) in enumerate(zip(['o', 'x'], ['Train', 'Test'])):\n",
    "    ax.scatter(data[labels==i, 0], data[labels==i, 1], color='k', s=10, marker=marker, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engines customizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine\n",
    "\n",
    "# Esto es lo que hace el engine de entrenamiento\n",
    "def train_one_step(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch\n",
    "    yhat = model.forward(x)\n",
    "    loss = criterion(yhat, y.unsqueeze(1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item() # Este output puede llamar luego como trainer.state.output\n",
    "\n",
    "# Esto es lo que hace el engine de evaluación\n",
    "def evaluate_one_step(engine, batch):\n",
    "    with torch.no_grad():\n",
    "        x, y = batch\n",
    "        yhat = model.forward(x)\n",
    "        yhat = (torch.sigmoid(yhat) > 0.5).float()\n",
    "        return yhat, y.unsqueeze(1)\n",
    "\n",
    "trainer = Engine(train_one_step)\n",
    "evaluator = Engine(evaluate_one_step)\n",
    "for name, metric in metrics.items():\n",
    "    metric.attach(evaluator, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch, Ignite y Tensorboard\n",
    "\n",
    "Podemos usar la herramienta [tensorboard](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html) para visualizar el entrenamiento de la red en vivo y/o comparar distintos entrenamientos\n",
    "\n",
    "- Instalar tensorboard versión 1.15 o mayor con conda\n",
    "\n",
    "- Escribir en un terminal\n",
    "\n",
    "        tensorboard --logdir=/tmp/tensorboard/\n",
    "\n",
    "- Apuntar el navegador a \n",
    "\n",
    "        https://localhost:6006 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Loss\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "torch.manual_seed(1234) # Inicialización\n",
    "neurons = [2, 10, 1]\n",
    "model = MultiLayerPerceptron(neurons)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "max_epochs = 100  \n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion) # Creo un engine para entrenar\n",
    "metrics = {'Loss': Loss(criterion)}\n",
    "evaluator = create_supervised_evaluator(model, metrics=metrics) # Creo un engine para validar\n",
    "\n",
    "\n",
    "with SummaryWriter(log_dir='/tmp/tensorboard/run1') as writer:\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED(every=1)) # Cada 10 epocas\n",
    "    def log_results(engine):\n",
    "        evaluator.run(torch_train_loader) # Evaluo el conjunto de entrenamiento\n",
    "        loss = evaluator.state.metrics['Loss']\n",
    "        #print(f\"Epoca: {engine.state.epoch} \\t Train Loss: {loss:.2f}\")\n",
    "        writer.add_scalar(\"train/loss\", loss, engine.state.epoch)\n",
    "        \n",
    "    @trainer.on(Events.EPOCH_COMPLETED(every=1)) # Cada 10 epocas\n",
    "    def log_results(engine):\n",
    "        evaluator.run(torch_valid_loader) # Evaluo el conjunto de entrenamiento\n",
    "        loss = evaluator.state.metrics['Loss']\n",
    "        #print(f\"Epoca: {engine.state.epoch} \\t Valid Loss: {loss:.2f}\")\n",
    "        writer.add_scalar(\"valid/loss\", loss, engine.state.epoch)\n",
    "\n",
    "    best_model_handler = ModelCheckpoint(dirname='.', require_empty=False, filename_prefix=\"best\", n_saved=1,\n",
    "                                         score_function=lambda engine: -engine.state.metrics['Loss'],\n",
    "                                         score_name=\"val_loss\")\n",
    "\n",
    "    evaluator.add_event_handler(Events.COMPLETED, # Esto se ejecuta cada ves que termine el loop de validación\n",
    "                                best_model_handler, {'mymodel': model})\n",
    "\n",
    "    trainer.run(torch_train_loader, max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
