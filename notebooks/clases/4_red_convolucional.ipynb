{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Convolucionales\n",
    "\n",
    "[Slides 49-88](https://docs.google.com/presentation/d/1IJ2n8X4w8pvzNLmpJB-ms6-GDHWthfsJTFuyUqHfXg8/edit#slide=id.g3a1a71fe7e_8_192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Convolucional en PyTorch\n",
    "\n",
    "Las redes neuronales convolucionales utilizan principalmente tres tipos de capas\n",
    "\n",
    "## [Capas convolucionales](https://pytorch.org/docs/stable/nn.html#convolution-layers)\n",
    "\n",
    "- Las neuronas de estas capas se organizan en filtros \n",
    "- Se realiza la correlación cruzada entre la imagen de entrada y los filtros\n",
    "- Existen capas convolucionales 1D, 2D y 3D\n",
    "\n",
    "\n",
    "[Visualización de convoluciones con distintos tamaños, strides, paddings, dilations](https://github.com/vdumoulin/conv_arithmetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los argumentos de la capa convolución de dos dimensiones son:\n",
    "\n",
    "```python\n",
    "torch.nn.Conv2d(in_channels, #Cantidad de canales de la imagen de entrada\n",
    "                out_channels, #Cantidad de bancos de filtro\n",
    "                kernel_size, #Tamaño de los filtros (entero o tupla)\n",
    "                stride=1, #Paso de los filtros\n",
    "                padding=0, #Cantidad de filas y columnas para agregar a la entrada antes de filtrar\n",
    "                dilation=1, #Espacio entre los pixeles de los filtros\n",
    "                groups=1, #Configuración cruzada entre filtros de entrada y salida\n",
    "                bias=True,  #Utilizar sesgo (b)\n",
    "                padding_mode='zeros' #Especifica como agregar nuevas filas/columnas (ver padding)\n",
    "                )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Capas de pooling](https://pytorch.org/docs/stable/nn.html#pooling-layers)\n",
    "\n",
    "- Capa que reduce la dimensión (tamaño) de su entrada\n",
    "- Se usa tipicamente luego de una capa de convolución \"activada\"\n",
    "- Realiza una operación no entrenable: \n",
    "    - Promedio de los píxeles en una región (kernel_size=2, stride=2)\n",
    "    \n",
    "            1 2 1 0\n",
    "            2 3 1 2      2.00 1.00\n",
    "            0 1 0 1      0.75 0.25\n",
    "            2 0 0 0\n",
    "            \n",
    "    - Máximo de los pixeles en una región (kernel_size=2, stride=2)\n",
    "   \n",
    "            1 2 1 0\n",
    "            2 3 1 2      3 2\n",
    "            0 1 0 1      2 1\n",
    "            2 0 0 0\n",
    "- Estas capas ayudan a reducir la complejidad del modelo\n",
    "- También otorgan \"invarianza local a la traslación\", es decir que la posición donde estaba el patrón es menos relevante luego de aplicar pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los argumentos de MaxPooling para entradas de dos dimensiones son:\n",
    "\n",
    "```python\n",
    "torch.nn.MaxPool2d(kernel_size, # Mismo significado que en Conv2d\n",
    "                   stride=None, # Mismo significado que en Conv2d\n",
    "                   padding=0, #Mismo significado que en Conv2d\n",
    "                   dilation=1, #Mismo significado que en Conv2d\n",
    "                   return_indices=False, #Solo necesario para hacer unpooling\n",
    "                   ceil_mode=False #Usar ceil en lugar de floor para calcular el tamaño de la salida\n",
    "                  )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Capas completamente conectadas](https://pytorch.org/docs/stable/nn.html#torch.nn.Linear)\n",
    "\n",
    "- Idénticas a las usadas en redes tipo MLP\n",
    "- Realizan la operación: $Z = WX + b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los argumentos son:\n",
    "\n",
    "```python\n",
    "torch.nn.Linear(in_features, #Neuronas en la entrada\n",
    "                out_features,  #Neuronas en la salida\n",
    "                bias=True  #Utilizar sesgo (b)\n",
    "                )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Torchvision](https://pytorch.org/docs/stable/torchvision/index.html)\n",
    "\n",
    "Es una librería utilitaria de PyTorch que facilita considerablemente el trabajo con imágenes\n",
    "\n",
    "- Funcionalidad para descargar sets de benchmark: MNIST, CIFAR, IMAGENET, ...\n",
    "- Modelos clásicos pre-entrenados: AlexNet, VGG, GoogLeNet, ResNet\n",
    "- Funciones para importar imágenes en distintos formatos\n",
    "- Funciones de transformación para hacer aumentación de datos en imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo: Base de datos de imágenes de dígitos manuscritos MNIST\n",
    "\n",
    "- Imágenes de 28x28 píxeles en escala de grises\n",
    "- Diez categorías: Dígitos manuscritos del cero al nueve\n",
    "- 60.000 imágenes de entrenamiento, 10.000 imágenes de prueba\n",
    "- Por defecto las imágenes vienen en [formato PIL](https://pillow.readthedocs.io/en/stable/) (entero 8bit), usamos la transformación [`ToTensor()`](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.ToTensor) para convertirla a tensor en float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "mnist_train_data = torchvision.datasets.MNIST(root='~/datasets/',\n",
    "                                              train=True, download=True, \n",
    "                                              transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "mnist_test_data = torchvision.datasets.MNIST(root='~/datasets/',\n",
    "                                             train=False, download=True, \n",
    "                                             transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "image, label = mnist_train_data[0]\n",
    "display(len(mnist_train_data), type(image), image.dtype, type(label))\n",
    "fig, ax = plt.subplots(1, 10, figsize=(8, 1.5), tight_layout=True)\n",
    "idx = np.random.permutation(len(mnist_train_data))[:10]\n",
    "for k in range(10):\n",
    "    image, label = mnist_train_data[idx[k]]\n",
    "    ax[k].imshow(image[0, :, :].numpy(), cmap=plt.cm.Greys_r)\n",
    "    ax[k].axis('off');\n",
    "    ax[k].set_title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders\n",
    "\n",
    "Creamos dataloaders de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset, DataLoader\n",
    "import sklearn.model_selection\n",
    "\n",
    "# Set de entrenamiento y validación estratíficados\n",
    "sss = sklearn.model_selection.StratifiedShuffleSplit(train_size=0.75).split(mnist_train_data.data, \n",
    "                                                                            mnist_train_data.targets)\n",
    "train_idx, valid_idx = next(sss)\n",
    "\n",
    "# Data loader de entrenamiento\n",
    "train_dataset = Subset(mnist_train_data, train_idx)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "\n",
    "# Data loader de validación\n",
    "valid_dataset = Subset(mnist_train_data, valid_idx)\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mi primera red convolucional para clasificar en pytorch\n",
    "\n",
    "Clasificaremos la base de datos MNIST \n",
    "\n",
    "Para esto implementaremos la clásica arquitectura Lenet5\n",
    "\n",
    "<img src=\"img/LeNet5.png\" width=\"800\">\n",
    "\n",
    "La arquitectura considera\n",
    "- Dos capas convolucionales con 8 y 16 bancos de filtros, respectivamente\n",
    "- Las capas convolucionales usan filtros de 5x5 píxeles\n",
    "- Se usa max-pooling de tamaño 2x2 y stride 2\n",
    "- La primera capa convolucional espera un minibatch de imágenes de 1 canal (blanco y negro)\n",
    "- Usaremos la función de activación [Rectified Linear Unit (ReLU)](https://pytorch.org/docs/stable/nn.html#relu)\n",
    "- Se usan tres capas completamente conectadas con 120, 84 y 10 neuronas, respectivamente\n",
    "\n",
    "> Podemos usar `reshape` o `view` para convertir un tensor de 4 dimensiones a dos dimensiones.  Esto prepara un tensor que sale de una capa convolucional (o pooling) para ingresarlo a las capas completamente conectadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Lenet5(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(type(self), self).__init__()\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    \n",
    "model = Lenet5()\n",
    "display(model)\n",
    "model.forward(mnist_train_data[0][0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación multiclase en PyTorch\n",
    "\n",
    "Para hacer clasificación con **más de dos categorías** usamos la [entropía cruzada](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss)\n",
    "\n",
    "```python\n",
    "    torch.nn.CrossEntropyLoss()\n",
    "```\n",
    "\n",
    "- Si el problema de clasificación es de $M$ categorías la última capa de la red debe tener $M$ neuronas\n",
    "- Adicionalmente no se debe usar función de activación ya que `CrossEntropyLoss` la aplica de forma interna\n",
    "\n",
    "Para evaluar la red debemos aplicar de forma manual \n",
    "- `torch.nn.Softmax(dim=1)`\n",
    "- `torch.nn.LogSoftmax(dim=1)`\n",
    "\n",
    "a la salida de la red\n",
    "\n",
    "> Luego podemos usar el atributo `argmax(dim=1)` para encontrar la clase más probable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradiente descendente con paso adaptivo\n",
    "\n",
    "Para acelerar el entrenamiento podemos usar un algoritmo de [gradiente descendente con paso adaptivo](https://arxiv.org/abs/1609.04747)\n",
    "\n",
    "Un ejemplo ampliamente usado es [Adam](https://arxiv.org/abs/1412.6980)\n",
    "\n",
    "- Se utiliza la historia de los gradientes\n",
    "- Se utiliza momentum (inercia)\n",
    "- Cada parámetro tiene un paso distinto\n",
    "\n",
    "```python\n",
    "    torch.optim.Adam(params,  #Parámetros de la red neuronal\n",
    "                     lr=0.001,  #Tasa de aprendizaje inicial\n",
    "                     betas=(0.9, 0.999),  #Factores de olvido de los gradientes históricos\n",
    "                     eps=1e-08, #Término para evitar división por cero\n",
    "                     weight_decay=0, #Regulariza los pesos de la red si es mayor que cero\n",
    "                     amsgrad=False #Corrección para mejorar la convergencia de Adam en ciertos casos\n",
    "                     )\n",
    "```\n",
    "\n",
    "**Atención**\n",
    "\n",
    "Esta es un área de investigación activa. [Papers recientes indican que Adam llega a un óptimo más rápido que SGD, pero ese óptimo podría no ser mejor que el obtenido por SGD](https://arxiv.org/abs/1712.07628)\n",
    "\n",
    "> Siempre prueba tus redes con distintos optimizadores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de la red convolucional\n",
    "\n",
    "- Si tenemos acceso a una GPU podemos usar el atributo `.cuda()` o `.to()` para enviar el modelo y los datos a la GPU para acelerar los cálculos\n",
    "- Actualizamos los parámetros en el conjunto de entrenamiento\n",
    "- Medimos la convergencia en el conjunto de validación\n",
    "- Guardamos el modelo con mejor error de validación\n",
    "- Usaremos `ignite` y `Tensorboard` para entrenar. Guardaremos los entrenamientos en `/tmp/tensorboard/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Loss, Accuracy\n",
    "\n",
    "model = Lenet5()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "max_epochs = 100  \n",
    "device = torch.device('cpu')\n",
    "#device = torch.device('cuda:0')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Esto es lo que hace el engine de entrenamiento\n",
    "def train_one_step(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    yhat = model.forward(x)\n",
    "    loss = criterion(yhat, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item() # Este output puede llamar luego como trainer.state.output\n",
    "\n",
    "# Esto es lo que hace el engine de evaluación\n",
    "def evaluate_one_step(engine, batch):\n",
    "    with torch.no_grad():\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        yhat = model.forward(x)\n",
    "        #loss = criterion(yhat, y)\n",
    "        return yhat, y\n",
    "\n",
    "trainer = Engine(train_one_step)\n",
    "evaluator = Engine(evaluate_one_step)\n",
    "metrics = {'Loss': Loss(criterion), 'Acc': Accuracy()}\n",
    "for name, metric in metrics.items():\n",
    "    metric.attach(evaluator, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "\n",
    "# Contexto de escritura de datos para tensorboard\n",
    "with SummaryWriter(log_dir=f'/tmp/tensorboard/run{time.time_ns()}') as writer:\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED(every=1)) # Cada 1 epocas\n",
    "    def log_results(engine):\n",
    "        # Evaluo el conjunto de entrenamiento\n",
    "        evaluator.run(train_loader) \n",
    "        writer.add_scalar(\"train/loss\", evaluator.state.metrics['Loss'], engine.state.epoch)\n",
    "        writer.add_scalar(\"train/accy\", evaluator.state.metrics['Acc'], engine.state.epoch)\n",
    "        # Evaluo el conjunto de validación\n",
    "        evaluator.run(valid_loader) \n",
    "        writer.add_scalar(\"valid/loss\", evaluator.state.metrics['Loss'], engine.state.epoch)\n",
    "        writer.add_scalar(\"valid/accy\", evaluator.state.metrics['Acc'], engine.state.epoch)\n",
    "    # Guardo el mejor modelo en validación\n",
    "    best_model_handler = ModelCheckpoint(dirname='.', require_empty=False, filename_prefix=\"best\", n_saved=1,\n",
    "                                         score_function=lambda engine: -engine.state.metrics['Loss'],\n",
    "                                         score_name=\"val_loss\")\n",
    "\n",
    "    # Lo siguiente se ejecuta cada ves que termine el loop de validación\n",
    "    evaluator.add_event_handler(Events.COMPLETED, \n",
    "                                best_model_handler, {'lenet5': model})\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluando la red en el conjunto de test\n",
    "\n",
    "Primero recuperamos la red con menor costo de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lenet5()\n",
    "model.load_state_dict(torch.load('best_lenet5_val_loss=-0.9585.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haremos la evaluación final del a red en el conjunto de prueba/test\n",
    "\n",
    "Iteramos sobre el conjunto y guardamos las predicciones de la red\n",
    "\n",
    "Con esto podemos construir una matriz de confusión y un reporte usando las herramientas de `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(mnist_test_data, shuffle=False, batch_size=512)\n",
    "\n",
    "test_targets = mnist_test_data.targets.numpy()\n",
    "prediction_test = []\n",
    "for mbdata, label in test_loader:\n",
    "    logits = model.forward(mbdata)\n",
    "    prediction_test.append(logits.argmax(dim=1).detach().numpy())\n",
    "prediction_test = np.concatenate(prediction_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(test_targets, prediction_test)\n",
    "display(cm)\n",
    "\n",
    "print(classification_report(test_targets, prediction_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de errores\n",
    "\n",
    "Luego de evaluar la red podemos estudiar sus errores con el objeto de mejorar el modelo\n",
    "\n",
    "Para problemas con imágenes es muy recomendable visualizar los ejemplos mal predichos por la red\n",
    "\n",
    "Esto podría revelar\n",
    "- Imágenes mal etiquetadas: Podemos cambiar su etiqueta y re-entrenar/re-evaluar\n",
    "- Errores sistemáticos del modelo: Por ejemplo que siempre se equivoque con una clase u objeto en particular\n",
    "\n",
    "Observemos algunos ejemplos mal clasificados\n",
    "\n",
    "- Las imágenes corresponden a `digit` que no fueron predichos como `digit`\n",
    "- El título de la imagen tiene la etiqueta predicha por la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = 8\n",
    "idx = np.where((test_targets == digit) & ~(prediction_test == digit))[0]\n",
    "\n",
    "fig, ax = plt.subplots(1, 10, figsize=(8, 1.5), tight_layout=True)\n",
    "for i in range(10):\n",
    "    ax[i].imshow(mnist_test_data[idx[i]][0].numpy()[0, :, :], cmap=plt.cm.Greys_r)\n",
    "    ax[i].set_title(prediction_test[idx[i]])\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puede ser de interés analizar las probabilidades asignadas por la red\n",
    "\n",
    "Para esto debemos aplicar activación Softmax a la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = mnist_test_data[idx[1]]\n",
    "# Usamos unsqueeze para convertirlo en un minibatch de 1 elemento:\n",
    "y = torch.nn.Softmax(dim=1)(model.forward(image.unsqueeze(0)))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(5, 2), tight_layout=True)\n",
    "ax[0].bar(range(10), height=y.detach().numpy()[0])\n",
    "ax[0].set_xticks(range(10))\n",
    "ax[1].set_title(\"Etiqueta: %d\" %(label))\n",
    "ax[1].imshow(image.numpy()[0, :, :], cmap=plt.cm.Greys_r);\n",
    "ax[1].axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando los filtros aprendidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.conv1.weight.data.numpy()\n",
    "M = w.shape[0]\n",
    "fig, ax = plt.subplots(1, M, figsize=(7, 2), tight_layout=True)\n",
    "\n",
    "for i in range(M):    \n",
    "    ax[i].imshow(w[i, 0, :, :])\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
