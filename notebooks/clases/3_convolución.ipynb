{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento digital de imágenes\n",
    "\n",
    "Una imagen es una colección de pixeles ordenados\n",
    "\n",
    "En estándar RGB cada pixel corresponde a 3 valores enteros de 8 bit (256 niveles). Combinándolos formamos colores (aproximadamente 16.7M)\n",
    "\n",
    "Otra codificación usual para los pixeles consiste en usar un número entre cero y uno para cada canal (color)\n",
    "\n",
    "El estándar RGBA añade un canal que representa la opacidad\n",
    "\n",
    "Las imágenes en escala de grises y sin opacidad se pueden representar usando un canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread('img/cameraman.png')\n",
    "\n",
    "def to_grayscale(img):\n",
    "    return np.dot(img[:, :, :3], \n",
    "                  np.array([0.2989, 0.587, 0.114]))\n",
    "\n",
    "img_bw = to_grayscale(img)\n",
    "\n",
    "display(img_bw.shape)\n",
    "display(img_bw.dtype)\n",
    "\n",
    "plt.figure(figsize=(4, 4), tight_layout=True)\n",
    "plt.imshow(img_bw, cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nuestros sistemas digitales una imagen es una arreglo multidimensional y podemos operarlo como tal\n",
    "\n",
    "¿A qué corresponde este segmento del arreglo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subimg = np.copy(img_bw[50:100, 120:180])\n",
    "display(subimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3), tight_layout=True)\n",
    "plt.imshow(subimg, cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Y este segmento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(6, 3), tight_layout=True)\n",
    "ax[1].plot(subimg[30, :])\n",
    "ax[0].imshow(subimg[30:31, :], cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolución  y correlación cruzada discreta\n",
    "\n",
    "Una herramienta clásica de procesamiento digital de señales es la **convolución**\n",
    "\n",
    "La operación de convolución entre dos señales unidimensionales discretas es\n",
    "\n",
    "$$\n",
    "(f * g) [n] = \\sum_{m=-\\infty}^\\infty  f[m] g[n-m]\n",
    "$$\n",
    "\n",
    "y la operación de correlación cruzada es\n",
    "\n",
    "$$\n",
    "(f \\star g) [n] = \\sum_{m=-\\infty}^\\infty  f[m] g[m+n]\n",
    "$$\n",
    "\n",
    "> Para ambas operaciones el resultado es una nueva señal que también depende de  $n$\n",
    "\n",
    "\n",
    "\n",
    "Por ejemplo el elemento $0$ de $f\\star g$ se calcula como\n",
    "\n",
    "    f[0] g[0] + f[1] g[1] + f[2] g[2] + ...\n",
    "\n",
    "Luego el elemento $1$ sería\n",
    "\n",
    "    f[0] g[1] + f[1] g[2] + f[2] g[3] + ...\n",
    "    \n",
    "¿Cómo se ve esta operación graficamente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "fig, ax = plt.subplots(2, figsize=(7, 4))\n",
    "ax2 = ax[0].twinx()\n",
    "\n",
    "def filt(k):\n",
    "    kernel = np.zeros(shape=(len(data),))\n",
    "    kernel[k:k+5] = 1\n",
    "    #kernel[k] = 1.; kernel[k+1] = -1.\n",
    "    return kernel\n",
    "\n",
    "data = subimg[0, :]\n",
    "true_filt = filt(0)[np.absolute(filt(0)) >0]\n",
    "display(true_filt)\n",
    "conv_s = scipy.signal.correlate(data, true_filt, mode='valid')\n",
    "\n",
    "\n",
    "def update(k): \n",
    "    ax[0].cla(); ax[1].cla(); ax2.cla();\n",
    "    ax[0].plot(data)\n",
    "    ax2.plot(filt(k), c='r')\n",
    "    ax[1].plot(conv_s); \n",
    "    ax[1].scatter(k, conv_s[k], s=100, c='k')\n",
    "    \n",
    "anim = animation.FuncAnimation(fig, update, frames=len(conv_s), interval=200, blit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado de imágenes con convoluciones\n",
    "\n",
    "Se puede extender el concepto de convolución a dos dimensiones\n",
    "$$\n",
    "(I_1 * I_2) [n_1, n_2] = \\sum_{m_1=-\\infty}^\\infty \\sum_{m_2=-\\infty}^\\infty I_1[m_1, m_2] I_2[n_1-m_2, n_2 - m_2]\n",
    "$$\n",
    "\n",
    "donde $n_1$ es el índice de las filas y $n_2$ es el índice de las columnas\n",
    "\n",
    "#### La convolución entre dos imágenes es una nueva imagen\n",
    "\n",
    "La imagen $I_1$ es la entrada\n",
    "\n",
    "La imagen $I_2$ se denomina filtro o kernel de la convolución\n",
    "\n",
    "La imagen resultante es la imagen filtrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtro pasa-bajo\n",
    "\n",
    "Suaviza, elimina los detalles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 3\n",
    "filt = np.ones(shape=(D, D))\n",
    "\n",
    "display(filt)\n",
    "img_res = scipy.signal.correlate2d(subimg, filt/np.sum(filt), mode='valid')\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(8, 3), tight_layout=True)\n",
    "ax[0].imshow(subimg, cmap=plt.cm.Greys_r)\n",
    "ax[1].imshow(filt, cmap=plt.cm.Greys_r)\n",
    "ax[2].imshow(img_res, cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtro pasa-alto\n",
    "\n",
    "Resalta los cambios bruscos, elimina las partes \"planas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = np.array([[1., -1.]]*2)\n",
    "display(filt)\n",
    "img_res = scipy.signal.correlate2d(subimg, filt, mode='valid')\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(8, 3), tight_layout=True)\n",
    "ax[0].imshow(subimg, cmap=plt.cm.Greys_r)\n",
    "ax[1].imshow(filt, cmap=plt.cm.Greys_r)\n",
    "ax[2].imshow(img_res, cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Detector de patillas?\n",
    "\n",
    "Detecta patillas de fotografos mirando al horizonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = np.ones(shape=(11, 11))\n",
    "filt[:9, 2:9] = 0\n",
    "display(filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_res = scipy.signal.correlate2d(subimg, filt-np.mean(filt), mode='valid')\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(8, 3), tight_layout=True)\n",
    "ax[0].imshow(subimg, cmap=plt.cm.Greys_r)\n",
    "maxloc = np.unravel_index(np.argmax(img_res), shape=img_res.shape)\n",
    "ax[0].scatter(maxloc[1]+filt.shape[0]//2, maxloc[0]+filt.shape[1]//2, c='r', s=20)\n",
    "ax[1].imshow(filt, cmap=plt.cm.Greys_r)\n",
    "ax[2].imshow(img_res, cmap=plt.cm.Reds);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En realidad el filtro se activa con cualquier cosa con forma de \"U\"\n",
    "\n",
    "El punto es:\n",
    "\n",
    "> Podríamos aprender filtros para detectar objetos específicos\n",
    "\n",
    "En ese caso:\n",
    "\n",
    "> Necesitamos aprender los valores de los \"píxeles\" del kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visión computacional\n",
    "\n",
    "La [visión computacional](http://szeliski.org/Book/) es un campo de investigación que busca que los computadores sean capaces de \"comprender\" el contenido presente en imágenes digitales y video\n",
    "\n",
    "#### Objetivo: \n",
    "\n",
    "> Automatizar tareas realizas por el sistema visual humano\n",
    "\n",
    "- Clasificación y Reconocimiento: ¿A qué categoría corresponde el patrón en la imagen?\n",
    "- Detección, Localización y Segmentación: ¿Dónde está el patrón en la imagen? \n",
    "- [Estimación de pose](https://modelzoo.co/blog/deep-learning-models-and-code-for-pose-estimation)\n",
    "- [Reconstrucción](https://www.youtube.com/watch?v=gg0F5JjKmhA), [super-resolución](https://www.extremetech.com/extreme/132950-csi-style-super-resolution-image-enlargment-yeeaaaah) y [síntesis](https://tcwang0509.github.io/pix2pixHD/)\n",
    "- ...\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/detection-and-segmentation-through-convnets-47aa42de27ea\"><img src=\"https://miro.medium.com/max/800/1*SNvD04dEFIDwNAqSXLQC_g.jpeg\" width=\"600\"></a>\n",
    "\n",
    "\n",
    "#### Aplicaciones\n",
    "\n",
    "- [Medicina](https://www.rsipvision.com/medical-segmentation/)\n",
    "- [Navegación autónoma](https://www.youtube.com/watch?v=H7Ym3DMSGms)\n",
    "- [Sistemas de control de tráfico](https://www.youtube.com/watch?v=jxhAWuImxS8)\n",
    "- [Realidad aumentada](https://www.youtube.com/watch?v=r9hVypi_6TQ)\n",
    "- [Agricultura y forestal](https://medium.com/@awangenh/mapping-weeds-and-crops-in-precision-agriculture-with-convolutional-neural-networks-138dab87ba00)\n",
    "- [...](https://www.cs.ubc.ca/~lowe/vision.html)\n",
    "\n",
    "#### Herramientas\n",
    "\n",
    "- Procesamiento digital de imágenes\n",
    "- Optimización, Estadística \n",
    "- Machine learning y en particular  **Redes Neuronales Convolucionales** \n",
    "\n",
    "\n",
    "#### Desafios\n",
    "\n",
    "- Algoritmos invariantes a los cambios de Iluminación\n",
    "- Algoritmos invariantes a los cambios de escala y perspectiva (deformación)\n",
    "- Algoritmos robustos contra la oclusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
